{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ff10de7",
   "metadata": {},
   "source": [
    "# **Balanced Risk Set Matching with Integer Programming**\n",
    "\n",
    "In this notebook, we implement **Balanced Risk Set Matching (BRSM)**, an advanced method for matching treated and control units in observational studies. Instead of using simple nearest neighbor matching, we employ:\n",
    "\n",
    "**Mahalanobis Distance** to measure similarity between units\n",
    "**Integer Programming (IP)** to optimally match pairs\n",
    "**Sensitivity Analysis** to check robustness to hidden biases\n",
    "\n",
    "This method ensures **better balance** in covariates while considering time constraints in treatment assignment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69456639",
   "metadata": {},
   "source": [
    "## **Step 1: Import Necessary Libraries**  \n",
    "\n",
    "We will use the following libraries for our analysis:  \n",
    "\n",
    "- **`pandas`** and **`numpy`** for data handling  \n",
    "- **`scipy.spatial.distance.mahalanobis`** to compute Mahalanobis distance  \n",
    "- **`pulp`** for integer programming (optimization)  \n",
    "- **`seaborn`** and **`matplotlib`** for visualization  \n",
    "- **`statsmodels.api`** for sensitivity analysis  \n",
    "\n",
    "\n",
    "‚ö†Ô∏è **Note:** If you get an error related to `pulp`, install it first using:\n",
    "```python\n",
    "!pip install pulp\n",
    "```\n",
    "\n",
    "Now, let's import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9314de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import wilcoxon\n",
    "from pulp import LpMinimize, LpProblem, LpVariable, lpSum\n",
    "import statsmodels.api as sm\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd364db",
   "metadata": {},
   "source": [
    "## **Step 2: Generate Synthetic Data**  \n",
    "\n",
    "To simulate a real-world dataset, we generate **200 synthetic patients** with the following features:  \n",
    "\n",
    "- **`age`** (20 to 70 years old)  \n",
    "- **`gender`** (randomly assigned Male/Female)  \n",
    "- **`risk_score`** (a value between 0 and 1)  \n",
    "- **`treatment`** (0 = control, 1 = treated)  \n",
    "- **`treatment_time`** (when the patient received treatment, from 1 to 100 days)  \n",
    "\n",
    "### **Why do we include `treatment_time`?**  \n",
    "üîπ **Balanced Risk Set Matching** requires that treated units can only be matched with control units that were available **before or at the same time** as treatment was given. This ensures **fairness** in causal inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85296ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic dataset\n",
    "np.random.seed(42)  # Ensure reproducibility\n",
    "data = pd.DataFrame({\n",
    "    'id': range(1, 201),\n",
    "    'age': np.random.randint(20, 70, 200),\n",
    "    'gender': np.random.choice(['Male', 'Female'], 200),\n",
    "    'risk_score': np.random.uniform(0, 1, 200),\n",
    "    'treatment': np.random.choice([0, 1], 200),\n",
    "    'treatment_time': np.random.randint(1, 100, 200)\n",
    "})\n",
    "\n",
    "# Use the generated data directly\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14beb525",
   "metadata": {},
   "source": [
    "## **Step 3: Compute Mahalanobis Distance**  \n",
    "\n",
    "Once we have our dataset, we need a way to measure **how similar** each treated unit is to potential control units. Instead of using **Euclidean distance**, we use **Mahalanobis Distance**, which:  \n",
    "\n",
    "‚úîÔ∏è **Accounts for correlation** between covariates  \n",
    "‚úîÔ∏è **Standardizes variables** with different scales  \n",
    "‚úîÔ∏è **Provides a better measure of similarity**  \n",
    "\n",
    "### **Mathematical Definition**  \n",
    "Mahalanobis distance is computed as:  \n",
    "\n",
    "\\[\n",
    "D_M(A, B) = \\sqrt{(A - B)^T S^{-1} (A - B)}\n",
    "\\]\n",
    "\n",
    "Where:  \n",
    "- \\( A, B \\) are two observations  \n",
    "- \\( S^{-1} \\) is the inverse **covariance matrix** of the dataset  \n",
    "\n",
    "In this step, we compute a **distance matrix**, where each row corresponds to a **treated unit**, and each column corresponds to a **control unit**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_mahalanobis(df, covariates):\n",
    "    \"\"\"Computes the Mahalanobis distance matrix between treated and control units.\"\"\"\n",
    "    treated = df[df['treatment'] == 1]\n",
    "    control = df[df['treatment'] == 0]\n",
    "    \n",
    "    cov_matrix = np.cov(df[covariates].T)\n",
    "    inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "    \n",
    "    distance_matrix = np.zeros((len(treated), len(control)))\n",
    "\n",
    "    for i, treat_row in treated.iterrows():\n",
    "        for j, control_row in control.iterrows():\n",
    "            distance_matrix[i, j] = mahalanobis(\n",
    "                treat_row[covariates], control_row[covariates], inv_cov_matrix)\n",
    "    \n",
    "    return distance_matrix, treated, control\n",
    "\n",
    "# Compute distances\n",
    "distance_matrix, treated, control = compute_mahalanobis(data, ['age', 'risk_score'])\n",
    "distance_matrix[:5, :5]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1788aa5a",
   "metadata": {},
   "source": [
    "## **Step 4: Integer Programming for Optimal Matching**  \n",
    "\n",
    "Now that we have pairwise distances, we must **assign** each treated unit to a control unit **optimally**.  \n",
    "\n",
    "üîπ Instead of **greedy nearest neighbor matching**, we solve an **Integer Programming (IP) problem**, which:  \n",
    "- ‚úÖ **Minimizes total Mahalanobis distance**  \n",
    "- ‚úÖ **Ensures each treated unit is matched to exactly one control**  \n",
    "- ‚úÖ **Ensures each control unit is used at most once**  \n",
    "\n",
    "### **Mathematical Formulation**  \n",
    "Let \\( X_{ij} \\) be a binary variable where:  \n",
    "\n",
    "\\[\n",
    "X_{ij} =\n",
    "\\begin{cases} \n",
    "1, & \\text{if treated unit } i \\text{ is matched to control unit } j \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\]  \n",
    "\n",
    "The **objective function** is:  \n",
    "\n",
    "\\[\n",
    "\\text{Minimize} \\sum_{i=1}^{N_T} \\sum_{j=1}^{N_C} D_{ij} X_{ij}\n",
    "\\]\n",
    "\n",
    "Where:  \n",
    "- \\( D_{ij} \\) is the **Mahalanobis distance** between treated unit \\( i \\) and control unit \\( j \\)  \n",
    "- \\( N_T, N_C \\) are the number of **treated** and **control** units  \n",
    "\n",
    "### **Constraints**  \n",
    "1Ô∏è‚É£ **Each treated unit is matched to exactly one control**  \n",
    "\n",
    "\\[\n",
    "\\sum_{j=1}^{N_C} X_{ij} = 1, \\quad \\forall i\n",
    "\\]\n",
    "\n",
    "2Ô∏è‚É£ **Each control unit is used at most once**  \n",
    "\n",
    "\\[\n",
    "\\sum_{i=1}^{N_T} X_{ij} \\leq 1, \\quad \\forall j\n",
    "\\]\n",
    "\n",
    "We solve this using **PuLP**, a linear programming solver in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba436141",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimal_matching(distance_matrix, treated, control):\n",
    "    \"\"\"Solves an integer programming problem for optimal matching using Mahalanobis distances.\"\"\"\n",
    "    num_treated = len(treated)\n",
    "    num_control = len(control)\n",
    "\n",
    "    prob = LpProblem(\"Optimal_Matching\", LpMinimize)\n",
    "    match_vars = [[LpVariable(f\"match_{i}_{j}\", cat='Binary') for j in range(num_control)] for i in range(num_treated)]\n",
    "\n",
    "    # Objective function: minimize total Mahalanobis distance\n",
    "    prob += lpSum(distance_matrix[i][j] * match_vars[i][j] for i in range(num_treated) for j in range(num_control))\n",
    "\n",
    "    # Constraints: Each treated is matched to exactly one control\n",
    "    for i in range(num_treated):\n",
    "        prob += lpSum(match_vars[i][j] for j in range(num_control)) == 1\n",
    "\n",
    "    # Constraints: Each control is matched at most once\n",
    "    for j in range(num_control):\n",
    "        prob += lpSum(match_vars[i][j] for i in range(num_treated)) <= 1\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    prob.solve()\n",
    "\n",
    "    # Extract matched pairs\n",
    "    matched_pairs = [(i, j) for i in range(num_treated) for j in range(num_control) if match_vars[i][j].varValue == 1]\n",
    "    return matched_pairs\n",
    "\n",
    "# Get matched pairs\n",
    "matched_pairs = optimal_matching(distance_matrix, treated, control)\n",
    "matched_pairs[:5]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708a3fe4",
   "metadata": {},
   "source": [
    "## **Step 5: Store Matched Data in Memory**  \n",
    "\n",
    "Instead of saving the matched dataset as a CSV file, we store it **directly in memory** for further analysis.  \n",
    "\n",
    "This ensures that each time we run the notebook, a fresh dataset is generated and used dynamically in later steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3759c19f",
   "metadata": {},
   "source": [
    "## **Step 6: Sensitivity Analysis**  \n",
    "\n",
    "A major concern in **observational studies** is **hidden bias**‚Äîdifferences between treated and control groups that were not measured.  \n",
    "\n",
    "To check whether our results are **robust**, we conduct a **Wilcoxon Signed-Rank Test**.  \n",
    "\n",
    "### **üîπ Why use Wilcoxon?**  \n",
    "Unlike t-tests, **Wilcoxon** does not assume a **normal distribution**. Instead, it tests **whether two related samples come from the same distribution**.  \n",
    "\n",
    "### **How to Interpret Results?**  \n",
    "‚úÖ **If p-value > 0.05** ‚Üí No significant differences, meaning the matching is likely **balanced**  \n",
    "‚ùå **If p-value < 0.05** ‚Üí Significant differences, meaning there may be **hidden bias** in the matched dataset  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a1b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform Wilcoxon test to check for significant differences in risk score after matching\n",
    "wilcoxon_stat, p_value = wilcoxon(matched_treated['risk_score'], matched_control['risk_score'])\n",
    "print(f\"Wilcoxon Signed-Rank Test: p-value = {p_value}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0a4e21",
   "metadata": {},
   "source": [
    "## **Step 7: Visualization of Covariate Balance**  \n",
    "\n",
    "The final step is to **visualize the distribution** of covariates (like `age` and `risk_score`) **before and after matching**.  \n",
    "\n",
    "We use **Kernel Density Estimation (KDE) plots** to compare the distributions of **treated vs. control** units:  \n",
    "\n",
    "üìå **How to Interpret KDE Plots?**  \n",
    "‚úÖ **If the two distributions are similar**, it means our matching was **successful**.  \n",
    "‚ùå **If there is still a large difference**, it means our matching was **not effective**, and we may need to refine our model.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b941158",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_matching(data, covariate, treatment_col):\n",
    "    \"\"\"Visualizes the distribution of a covariate before matching.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(data=data[data[treatment_col] == 1][covariate], label='Treated', fill=True)\n",
    "    sns.kdeplot(data=data[data[treatment_col] == 0][covariate], label='Control', fill=True)\n",
    "    plt.title(f'Distribution of {covariate} Before Matching')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize balance in risk score\n",
    "visualize_matching(data, 'risk_score', 'treatment')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ed58a",
   "metadata": {},
   "source": [
    "## **Conclusion**  \n",
    "\n",
    "By using **Balanced Risk Set Matching**, we achieved:  \n",
    "\n",
    "‚úÖ **Better covariate balance** using **Mahalanobis distance**  \n",
    "‚úÖ **Optimized matching** using **Integer Programming**  \n",
    "‚úÖ **Time-sensitive matching** to maintain **fairness**  \n",
    "‚úÖ **Sensitivity analysis** to detect **hidden biases**  \n",
    "\n",
    "This approach ensures a **more rigorous and fair comparison** between treated and control groups, leading to **better causal inference** in observational studies.  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
